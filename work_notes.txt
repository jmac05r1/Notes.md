#######################################################################
# Onica-sso
#######################################################################
sso-list = list out accounts
sso-login (account) = logs  you into account
sso conosle = logs you into console

#######################################################################
# Runway
#######################################################################
runway plan
runway deploy
runway destroy

pipenv install markupsafe "==2.0.1" #  "fixed marksafe error"
or 
pipenv install markupsafe==2.0.1
pipenv install markupsafe="==2.0.1"
(removed runway from local machine) 
error fixes runway virtual env

pipenv sends command to pipshell like mysql

#######################################################################
# Terraform
#######################################################################
terraform init 
terraform plan "see before it deploys"
terraform apply "actually deploy"

#######################################################################
# Github Commands
#######################################################################
tpyical work flow 
making changes *locally*
staging changes
commiting changes

############################################################################
# creating git from local to remote
############################################################################
    git init && git checkout -b NAME (in local directory to initialize)
    touch README.md
    git commit -m 'NAME'
    git remote add origin https://github.com/USERNAME/NAME.git
    git branch -M main #NAME OF BRANCH
    git push -u origin main #PUSH FILES FROM LOCAL TO GIT

    git remote add origin git@github.com-onicagithub:##SSH URL####

    git branch -a # shows you the branches & remote branches conneted to 

############################################################################
# push to multiple remotes (github)
############################################################################
    # Add remote 1: GitHub.
        git remote add origin https://USERNAME@bitbucket.org/corpinfo/USERNAME-devops.git
    # Add remote 2: BitBucket.
        git remote add upstream https://github.com/USERNAME/fsproject.git

    # Create a new remote called "all" with the URL of the primary repo.
        git remote add all https://USERNAME@bitbucket.org/corpinfo/USERNAME-devops.git
    # Re-register the remote as a push URL.
        git remote set-url --add --push all https://github.com/USERNAME/fsproject.git
    # Add a push URL to a remote. This means that "git push" will also push to this git URL.
        git remote set-url --add --push all https://USERNAME@bitbucket.org/corpinfo/USERNAME-devops.git  
                    
    ###### reference in case of help https://jigarius.com/blog/multiple-git-remote-repositories ####    

.ssh config is set up with mulitple github accounts 
when using ssh to push need to match git@github.com-###### thats in config file


  
############################################################################
# IAM roles can be put into autoscaling group
# with IAM_INSTANCE_PROFILE (I usually create a generic poicy and then add correct polices from console while removein generic policy)
# this keeps the role in the auto launch config anytime a new serve is spun up (need to find how to insert correct policy at start)
############################################################################
### Launch Configuraiton ###
resource "aws_launch_configuration" "launch_config" {
  name_prefix                 = var.launch-config-name
  image_id                    = data.aws_ami.amibase.id
  instance_type               = var.instance-type
  key_name                    = var.instance-key-name
  iam_instance_profile        = "${aws_iam_instance_profile.ec2jmac_profile.name}" <--------
  security_groups             = ["${aws_security_group.ec2-rule.id}"]
  associate_public_ip_address = false

############################################################################
# Role Policy for SSM allows you to connect with session manager
############################################################################
["arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore",
"arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy",
"arn:aws:iam::aws:policy/AWSCodeCommitFullAccess",
"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess"]

############################################################################
# aws systems manager 
###############################
install cloudwatch package from console w/run command using name as " AmazonCloudWatchAgent"


############################################################################
# cloud watchagent install from console/ssh/session manager
###########################################################################
https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/install-CloudWatch-Agent-on-first-instance.html
Log into instance run (yum install amazon-cloudwatch-agent)

configure .json file usually in "/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-wizard
REFERENCE >> cloudwatch.txt

fetch file
sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -s -c file:config.json
REFERENCE >> cloudwatch.txt 

############################################################################
# Testing upload cloudwatch agent to configuraiton file to system manager
###########################################################################
Uploading the CloudWatch agent configuration file to Systems Manager Parameter Store
If you plan to use the SSM Agent to install the CloudWatch agent on servers, after you manually edit the CloudWatch agent configuration file, you can upload it to Systems Manager Parameter Store. To do so, use the Systems Manager put-parameter command.
To be able to store the file in Parameter Store, you must use an IAM role with sufficient permissions. For more information, see Create IAM roles and users for use with the CloudWatch agent.
Use the following command, where parameter name is the name to be used for this file in Parameter Store and configuration_file_pathname is the path and file name of the configuration file that you edited.
(((((aws ssm put-parameter --name "parameter name" --type "String" --value file://configuration_file_pathname)))))


#### STACKER ####
#### pipenv install is currently installed on mac (did it manual) ####
pip3 install stacker #inside folder to create stack inside directory
pipenv run stacker build -it -r us-west-2 common.env stack-definition.yaml
pipenv run stacker build -it -r REGION FILENAME.EVN STACK.yaml

#### destory stacks ####
## Cleanup

Once you are finished with this example, you can remove the stack
with `stacker destroy`:

```bash
pipenv run stacker destroy -ft -r us-west-1 common-us-west-1.env stacker_config.yaml
pipenv run stacker destroy -ft -r REGION ENVFILE YAMLFILE

#######################################################################
# Windows One liners
#######################################################################
* Open power shell *
Get-PSDrive - to list out drives
Get-Volume C - to get specific drive space

Once have extended in AWS-console
Run
"rescan" | diskpart > Get-PartitionSupportedSize -DriveLetter DRIVELETTER >  Resize-Partition -DriveLetter DRIVELETTER -Size SIZE 
                                                                          > or if wanting full size
                                                                          > Resize-Partition -DriveLetter DRIVELETTER -Size $(Get-PartitionSupportedSize -DriveLetter DRIVELETTER).SizeMax


#######################################################################
# git clone codecommit.  
#######################################################################

Just need to make sure iso-login first, then view their code commit page and do git clone



#######################################################################
# terraform cloud 
#######################################################################
need to make username - 4240
                        e-mail : @rackspace.com

#######################################################################
# search for tickets in jira
#######################################################################
https://nbdevs.atlassian.net/issues/?jql=project%20in%20(HX%2C%20MDT)%20AND%20summary%20~%20%22customer%20communication%22
 
 - use (project = "HX" and summary ~ "customer communication") with JQL search

 #######################################################################
# Linux Notes
#######################################################################
 fallocate -l 10G name.img
 tail -n1 /etc/mtab >> ((((two >> VERY IMPORTANT as it adds line to bottom of line vs ">" overwrites whole file)))) /etc/fstab
 mkfs.ext4 /dev/####1 creates filesytem for partition 
 mount /dev/xvdf1 /home2    explained: mount "partioton" on "directory"
 blkid = gets the UUID of volume/partition

Linux Creating a Partition Size Larger Than 2TB
        # (parted) parted /dev/#### (starts parted service/program)
        # (parted) mklabel gpt
        # (parted) unit TB
        # (parted) mkpart primary 0.00TB 3.00TB
        # (parted) print (((should list out from start to end of disk)))

((((((((((((((((((((((((  swaping data from one mount point to another with UUID ))))))))))))))))))))))))#server irv-pc101
. stop apache
. Create new EBS Volume (check to see if encrypted if so then encrypt)
. Attach ebs volume
. Use fdisk for creating new partition on new volume
. Format with ext4
. Mkdir /home2
. Mount /dev/#### /home2. Here xvdf1 is new partition.
. Rsync /home /home2. Dont know the syntax
. Verify
. Umount /home
. Update fstab for /home and use uuid of /dev/xvdf1
. Mount /home
. Verify
. Reboot

If needing to move files up a directory you need to cd to the directory that has everything
run command = shopt -s dotglob
then command = mv *.* /parentdirectory 
(dont forget to the delete old directory still in parent directory)
### using rsync 
    rsync -nav "test runs"
    rsync -av "deploy"

#######################################################################
# creating LVM
#######################################################################
vgs = volume group
lvs = logical volume
pvs = physical volume 
 

fdisk -l (list out partition on server)
create LVM on disks (format)
vgcreate VGNAME /dev/partition1 /dev/partition2 <-- creates volume group and pvs ()
vgdisplay -v (shows contents of lvm)
pvs (list out physical volumes)

lvcreate -l 100%free -n volume2-lv macvg (volume group)
make file system with mkfs.ext4 "LVPATH"

lvdisplay -v
--- Logical volume ---
  LV Path                /dev/macvg/volumetstfull

#######################################################################
# removal lvm
#######################################################################
Remove volume
  - lvremove Vg0/home
reduce volume group
  - vgreduce Vg0 /dev/nvme2n1p1
Remove physical volume
  - pvremove /dev/nvme2n1p1

At this time you will only have one physical volume (/dev/nvme0n1p5) and two logical volumes of /dev/vg0/root & /dev/vg0/swap
Once completed we will be ableto detatch and remove volume from console

Current status
#######################################################################
#  root@irv-pc101:~# lsblk -f
NAME         FSTYPE      LABEL UUID                                   MOUNTPOINT
nvme0n1
├─nvme0n1p1  ext4              dac20572-972b-4806-81f7-3bbae6c96b32   /boot
├─nvme0n1p2
└─nvme0n1p5  LVM2_member       ftJWo8-dCIE-o48b-8fzj-fidP-ddVy-c1d5oL
  ├─vg0-root ext4              be692ab9-2e21-4a74-b53b-1be36baf70cf   /
  ├─vg0-swap swap              7af6d904-40c8-4110-bc45-ea4778f08cec   [SWAP]
  └─vg0-home ext4              a9e1665b-0403-461e-8283-62e41e4cac31
nvme1n1
└─nvme1n1p1  ext4              f1c67403-312e-471a-9407-23e4c5b3af2c   /home
nvme2n1
└─nvme2n1p1  LVM2_member       CwoAZP-82h7-Ydm0-eC11-I6Fw-yAmt-4JDkjt
  └─vg0-home ext4              a9e1665b-0403-461e-8283-62e41e4cac31


  Disk /dev/nvme2n1: 2.5 TiB, 2735894167552 bytes, 5343543296 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0xbf60f0ff

Device         Boot Start        End    Sectors Size Id Type
/dev/nvme2n1p1       2048 4294967294 4294965247   2T 8e Linux LVM
#######################################################################

#######################################################################
# increase/expand disk size in linux NON LVM
#######################################################################
growpart /dev/xvda 1 (1 is the first partition from xvda, if multiple partitions "down the list" then it would be a different number)

file -s /dev/xvda* (to find out which filesystem its on then run the following "per filesystem")

xfs_growfs /dev/VOLUMEPartition
OR (depending on OS)
resize2fs /dev/VOLUMEPartition 


#######################################################################
# ssh with private key
#######################################################################
ssh -i "PRIVATEKEY" user@IP
ssh -i test.cer ec2-user@107.23.17.39

#######################################################################
# How to read/write usb drivers with exfat on linux systems
#######################################################################
need to install exfat packages
apt install exfat-fuse exfat-utils

#######################################################################
# certbot notes (renew SSL cert )
#######################################################################
certbot certonly -d owncloud.jmactx.com,www.owncloud.jmactx.com ((need to restart apache once complete))

#######################################################################
# Cross reference stacks using output
#######################################################################
Source output example:
  Outputs:
    AdminPatchRoleArn:
    Description: ARN of Role
    Export:
      Name: AdminPatchRoleArn
    Value: !GetAtt ['AdminPatchRole', 'Arn']  # yamllint disable-line rule:line-length
  
Destination: 
  Has to have the srouce referenced 
  stacks:
  ec2-patching-role:
    template_path: ../../08-patch-manager/cloudformation/patching-iam-role.yaml
    variables:
      <<: *common_parameters
      Region: ${region}

       actual line is ######  IamRole: ${output ec2-patching-role::AdminPatchRoleArn}
                                        (output is the name of the resource from stack "ec2-patching-role")
                                        (then the name of the actualy output NOT the name of "name")

#######################################################################
# when working on new repo and does not work try running these lines
#######################################################################
pipenv install --skip-lock
pipenv install

#######################################################################
# finding outputs from aws console for security groups
#######################################################################
look into s3 > correct bucket > find whats needed and use "open" feature at top of page

#######################################################################
# chrome profile & alfred configuration
#######################################################################
ls -lastrh ~/Library/Application\ Support/Google/Chrome # view profiles created
open -n -a "Google Chrome" --args --profile-directory="Profile 11" # alfred profile 

#######################################################################
# Python variables when referencing (path)
#######################################################################
runway stack in "runway"
path: hooks.s3_create_upload.create_upload
(FOLDER.FILE.FUNCTIONNAME)

.ENV file will have its variables in place for runway stack

#######################################################################
# Waf Creation using template and local files instead of URL from default template
#######################################################################
Need to find local files to download 
https://${S3Bucket}.s3.amazonaws.com/${KeyPrefix}/aws-waf-security-automations-webacl.template

${S3Bucket} & ${KeyPrefix} found in mappings of template (MAPPINGS IS KEY)


Mappings:
    SourceCode:
        General:
            TemplateBucket: 'solutions-reference'
            SourceBucket: 'solutions'
            KeyPrefix: 'aws-waf-security-automations/v3.2.0'

(((((S3Bucket: !FindInMap ["SourceCode", "General", "TemplateBucket"]))))))
(((((KeyPrefix: !FindInMap ["SourceCode", "General", "KeyPrefix"])))))            

Example: https://solutions-reference.s3.amazonaws.com/aws-waf-security-automations/v3.2.0/aws-waf-security-automations-webacl.template <---- is what to be downloaded


#######################################################################
# SElinux port list
#######################################################################
semanage port -l # to list all ports, use grep for specific service

#######################################################################
# fluentD configuration
#######################################################################
/etc/td-agent/td-agent.conf (configuration fiile)

<source>
  @type syslog
  port 10514
  tag system
</source>

<match **>
  @type cloudwatch_logs
  log_group_name fluentd-group-name
  log_stream_name stream_name
  auto_create_stream true
  region us-east-1
</match>

^^ configuration using a fluentD instance as proxy to send files to cloudwatch, files coming from rsyslog

#######################################################################
# creating syslog remote server
#######################################################################
1. Configure log location # create directory 
2. Open firewall # if needed or running software firewall
3. Install rsyslog
4. Configure rsyslog
5. Test ( need to create logs from other instances to destination ) # logger 'Test from IP###'

#######################################################################
# checks config file for syntax errors
#######################################################################
rsyslogd -f /etc/rsyslog.conf -N1

#######################################################################
# Remote syslog server
#######################################################################
syslog server 172.20.7.121

- /etc/rsyslog.conf
# Provides UDP syslog reception
# for parameters see http://www.rsyslog.com/doc/imudp.html
module(load="imudp") # needs to be done just once
input(type="imudp" port="51421")

# Provides TCP syslog reception
# for parameters see http://www.rsyslog.com/doc/imtcp.html
module(load="imtcp") # needs to be done just once
input(type="imtcp" port="51421")

# template
$template incoming-remote-logs,"/var/log/remotelogs/%HOSTNAME%/%PROGRAMNAME%.log"
*.* ?incoming-remote-logs # tells to run template

restart syslog
systemctl restart rsyslog

make sure its listening on correct port
[root@ip-172-20-7-121 syslog]# netstat -plnt | grep 51421
tcp        0      0 0.0.0.0:51421             0.0.0.0:*               LISTEN      59739/rsyslogd
tcp6       0      0 :::51421                  :::*                    LISTEN      59739/rsyslogd

Adds under the word "module" (putting at end of file does not work for some reason)
sudo sed -i "/####\ MODULES\ ####/a\n\n###RACKSPACE###\n# Provides UDP syslog reception\n# for parameters see http://www.rsyslog.com/doc/imudp.html\nmodule(load="imudp") # needs to be done just once\ninput(type="imudp" port="51421")\n# Provides TCP syslog reception\n# for parameters see http://www.rsyslog.com/doc/imtcp.html\nmodule(load="imtcp") # needs to be done just once\ninput(type="imtcp" port="51421")\n\n# template\n$template incoming-remote-logs,"/var/log/remotelogs/%HOSTNAME%/%PROGRAMNAME%.log"\n*.* ?incoming-remote-logs # tells to run template\n\n###END RACKSPACE###"  /etc/rsyslog.conf


########################################################################
# Client syslog server 
#######################################################################
syslog client 172.20.7.243

/etc/rsyslog.conf
# Rsyslog server IP (double @@ is for tcp sing @ is for udp)
# Rsyslog server IP
*.* @@172.20.7.121:51421 # @@ is for "tcp"  if sing "@" for udp

# Handle when syslog server is down
ActionQueueFileName queue # used to create queue files
ActionQueueMaxDiskSpace 1g # max size that queue files save to disk
ActionQueueSaveOnShutdown on # used to save in memory data if server syslog shuts down
ActionQueueType LinkedList # enables linklist in memory queue
ActionResumeRetryCount -1 # prevent syslog from dropping message if server not availbale

mgmt-vpc-linux-management-sg VPC-CIDR 172.20.0.0/16 #need to open "port"

#######################################################################
# SELinux issues
#######################################################################
# check what ports SELinux is allowing
sudo semanage port -l| grep syslog # to view what ports are allowed by SELinux

# enable 514 TCP on forwarders by default only allows UDP 514
semanage port -m -t syslogd_port_t -p tcp 514


#######################################################################
# FluentD configuration to CW on AWS EC2 instance "aggregator"
#######################################################################
td-agent --dry-run

/usr/sbin/td-agent-gem list # looks for plugins installed

td-agent -c /etc/td-agent/./td-agent.conf runs for errors

<source>
  @type tail
  path /var/log/remotelogs/*/*.log
  exclude_path ["/var/log/remotelogs/*/*.gz", "/var/log/remotelogs/*/*.zip"]
  pos_file /var/log/td-agent/apps.pos
  tag remote-logs
        <parse>
      @type grok
      grok_pattern %{CISCOTIMESTAMP:timestamp} %{URIHOST:host} %{GREEDYDATA:service} %{NUMBER}-%{MONTHNUM}-%{MONTHDAY} %{HOUR}:%{MINUTE}.%{SECOND} %{GREEDYDATA:message}
      time_format "%b %d %H:%M:%S"
   </parse>
</source>

<match remote-logs>
  @type cloudwatch_logs
  log_group_name fluentd-group-name
  log_stream_name stream_name
  auto_create_stream true
  region us-east-1
</match>

^^^^ when writing to disk from remote instance and then being sent out cloudwatch



#######################################################################
# when using td-agent -c /etc/td-agent/td-agent.conf
#######################################################################
2022-05-18 00:36:31 +0000 [info]: #0 starting fluentd worker pid=10889 ppid=10884 worker=0
2022-05-18 00:36:31 +0000 [info]: #0 following tail of /var/log/remotelogs/ip-172-20-7-201/journal.log
2022-05-18 00:36:31 +0000 [info]: #0 following tail of /var/log/remotelogs/ip-172-20-7-201/sshd.log
2022-05-18 00:36:31 +0000 [info]: #0 following tail of /var/log/remotelogs/ip-172-20-7-201/chronyd.log
2022-05-18 00:36:31 +0000 [info]: #0 [input_debug_agent] listening dRuby uri="druby://127.0.0.1:24230" object="Fluent::Engine" worker=0
2022-05-18 00:36:31 +0000 [info]: #0 [input_forward] listening port port=24224 bind="0.0.0.0"

had to edit /usr/lib/systemd/system/td-agent.service as root user, need to fix to run as td-agent user
fix is to change the /var/log/directory (from config file) users/group to td-agent:td-agent

#######################################################################
#  HA rsyslog on fwders (High availability)
#######################################################################
##Enable sending of logs over TCP add the following line:
*.* @@10.194.168.128:514
#Failover rsyslog server details (HA Mode) < -- sets HA mode
$ActionExecOnlyWhenPreviousIsSuspended on
& @@10.194.168.129:514
$ActionExecOnlyWhenPreviousIsSuspended off
#########################################
##Set disk queue when rsyslog server will be down:
$ActionQueueFileName queue
$ActionQueueMaxDiskSpace 1g
$ActionQueueSaveOnShutdown on
$ActionQueueType LinkedList
$ActionResumeRetryCount -1


#######################################################################
# redirect Phtech notes
#######################################################################
""IF statment""  
  Need to set rule under primary rule "around 90th on list in load-balancer php-s-LoadB-JK8JTGCARTDC in sitecore-prod"
    PATH IS: /group or /GROUP or /group < --- generally after the ".com/##"
      HOST IS: URL.com
      use "group" with / under condition
"" TEHN statment ""
  redirect to #{port} into field
    custom host   "which is the URL.com"
      copy evertyhing after (.com) right before (?)
        goes into host  
          path is everything after (?) no need to copy (?)

#######################################################################
# Increasing volume in windows that does not show in OS 
#######################################################################
Doing an increase on volume from console not reflecting correct size in disk management
Need to reboot instance if EBS volume being increased is NVME drive, can be found in disk management >  porperties (of volume) > events

#######################################################################
# Cross reference with modules
#######################################################################
/terraform/asg/asg.tf and /terraform/nlb/nlb.tf

Needing to reference an attachment from asg.tf to a loadbalancer of nlb.tf

asg.tf has a resource of "aws_autoscaling_attachment" that needs 
lb_target_group_arn = var.targetgroup_arn <-- needs to have a variable in variable file
                     ((((( variable "target_group_arn" {} )))))

nlb.tf has an output of .arn example 
output "lb_tg_arn" {value = resource.resourcename.arn}
                  (aws_lb_target_group.fluentd_lb_tg.arn)

from there you will use your module to point to another module
example: targetgroup_arn = "${module.modulename.outputname}
                           "${module.secondarymodule.lb_tg_arn}          

#######################################################################
# outputs also, need to outputs for stack that references module outputs 
#######################################################################
module output
output "scaling_name"   { value = aws_autoscaling_policy.scaling_policy.name }
               (((( output "sclaing_name" {value = resource.resoursename.name} )))))))

stack output 
output "autoscaling_name" { value = module.asg_nlb.scaling_name }
((((((((  output "mainnameblah" {value = module.moduleName.outputname } )))))))) 
      
